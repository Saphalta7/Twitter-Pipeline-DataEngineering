# Twitter-Pipeline-DataEngineering

This project is a complete Data Engineering project that uses Airflow and Python. We start by getting information from Twitter using its special tool called the Twitter API. Then, we use Python to organize and change the data the way we need it. After that, we put our Python code into action on Airflow or an EC2 instance, which are like virtual computers that can handle our data tasks. Finally, we save the finished results on Amazon S3, a storage service provided by Amazon. So, step by step, we extract data from Twitter, use Python to tidy it up, run our code on Airflow or EC2, and store the final outcome on Amazon S3.

